{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Herhalingslabo Classificatie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hoe weet je wanneer je welk algoritme best gebruikt ? Gebruik volgende handleiding:\n",
    "\n",
    "**KNearestNeighbours**\n",
    "- Geschikt voor classificatie en regressie\n",
    "- Voor kleine/middelgrote datasets\n",
    "- heel simpel, kan snel worden getrained\n",
    "- werkt niet goed voor datasets met heel veel features\n",
    "\n",
    "**Support Vector Machines**\n",
    "- Vooral een standaard voor binaire classificatie, of wanneer je een duidelijke marge wilt op classificatie (=het hoofddoel van het algoritme)\n",
    "- Voor kleine/middelgrote datasets\n",
    "- Is kostelijker om te trainen dan KNN, maar classificeert dan wel sneller\n",
    "- Kernel keuze en hyperparameter tuning zijn essentieel\n",
    "\n",
    "**Decision Trees**\n",
    "- Wanneer je een 'white box', 'explainable' model wilt\n",
    "- kan zowel numerieke als categorische features makkelijk aan\n",
    "- kan heel goed om met missende datapunten\n",
    "- het risico op overfitting is groot. Bij twijfel, gebruik een random forest\n",
    "\n",
    "**Random forest**\n",
    "- Zelfde voordelen als decision tree, minder risico op overfitting\n",
    "- Geschikt voor middelgrote/grote datasets\n",
    "- Geschikt voor data met (heel) veel features\n",
    "- Hebben uiteraard meer trainingstijd nodig dan een enkele decision tree\n",
    "\n",
    "**Adaboost**\n",
    "- Als data niet goed is gebalanceerd (niet evenveel items van elke klasse)\n",
    "- Vermijd een onderfit. Dit model is beter dan 1 enkele onderliggende decision tree\n",
    "\n",
    "**XGBoost**\n",
    "- XGBoost is bijna *altijd* een goede keuze\n",
    "- Middelgrote / grote datasets\n",
    "- Datasets met (heel) veel features\n",
    "- De implementatie van XGBoost staat, ondanks dat het een boosting algoritme is, toch deels parallellisatie toe.\n",
    "\n",
    "In de praktijk zijn er vaak meerdere goede keuzes. Het is belangrijk te weten waarom een bepaald model wel/niet een goede keuze zou zijn, en vervolgens de meest veelbelovende modellen te proberen en te kijken wat het beste werkt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wat is een kleine / middelgrote / grote dataset ?\n",
    "\n",
    "Uiteraard is dat een beetje afhankelijk van hoelang je bereid bent te wachten. In deze cursus gebruiken we de gangbare regel:\n",
    "- Klein: <10k\n",
    "- Middelgroot: 10k - 100k\n",
    "- Groot: >100k\n",
    "\n",
    "Dit is ongetwijfeld over een paar jaar volledig voorbijgestreefd. Besef dat je in real life dit altijd moet afwegen tegenover de beschikbare compute power, op een Raspberry Pi 3 zal een middelgrote dataset al een stevige trainingstijd hebben, terwijl dat kinderspel is op een cloud compute server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oefeningen\n",
    "\n",
    "Behandel de volgende 3 datasets - je kan ze downloaden vanop Digitap. Lees in, bekijk, en beoordeel welke algoritmes het meeste zin hebben. Pas de ML algoritmes toe en rapporteer de uiteindelijke score van je model.\n",
    "- Diabetes - i de 'outcome' kolom wordt aangegeven of mensen diabetes hebben\n",
    "- Customer Churn: in commerciÃ«le setting wordt vaak gesproken van 'churn', oftewel het aangeven in een soort diagram waar klanten in een process afhaken. Deze dataset bevat een 'churn' kolom die dat codeert.\n",
    "- Creditcard bevat data die reeds door een ander algoritme is gegaan, waardoor de kolommen geen herkenbare naam meer hebben. De laatste kolom wijst op fraude (1) of een valide transactie (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
